import{s as r,n as a}from"../chunks/scheduler.Cs0xm5t1.js";import{S as n,i as l,e as h,c,g as d,j as p,l as m,d as g}from"../chunks/index.odHI_-bW.js";const u=""+new URL("../assets/intro.CSyXUABa.png",import.meta.url).href,f=""+new URL("../assets/rast.BuaQUlGH.png",import.meta.url).href,w=""+new URL("../assets/shad.UmFbctmw.png",import.meta.url).href;function x(o){let e,i=`<h1 class="text-4xl font-bold text-gray-100 my-4 ">How does a 3D renderer work?</h1> <section class="text-lg text-gray-300 mb-4"><p class="font-semibold">authors : Lucien VILLARD &amp; Corentin SOLOIS</p></section> <h2 id="overview" class="text-2xl font-bold text-gray-100 mb-2">Introduction</h2> <p class="text-lg text-gray-300 mb-1">3D is everywhere in our new technology. Think of film (animation, VFX), video games (virtual reality, 3D animation) and even fields like architecture. But have you ever wondered how our computers transform 3D models into 2D images on the screen? This process is a sequence of algorithms, called the &quot;pipeline&quot;, executed by the 3D renderer. This series of instructions consists of 3 key steps: Vertex Shading, Rasterisation and Fragment Shading. In this article, we will review the 3 key steps to understand the basis of the 3D renderer.</p> <img src="${u}" alt="intro" class="w-full"/> <h2 id="overview" class="text-2xl font-bold text-gray-100 mb-2 mt-8">Vertex Shading</h2> <p class="text-lg text-gray-300 mb-1">First of all, it is very important to understand how 3D models are represented. It contains a set of triangles and their vertices. Each vertex is a point in a 3D space, so it can be represented by x, y and z coordinates. The Vertex Shading step consists of transforming each vertex of each 3D triangle into a vertex of 2D triangle relative to a camera. This process is repeated hundreds of thousands of times. And for a 120 fps game, imagine the number of calculations required.
    Although this may seem to be extreme, graphics cards (the main component for 3D rendering) are designed for this type of operation. With ten of sections that are asynchronous, computers are able to perform 35 trillion of operations per second. 
    To better understand this step, imagine a 3D world, say a classroom. We want to display it on a screen, which is a bit like taking a picture of that room. We need to convert a 3D point, e.g. on a table, into a screen position. To start with, we need to know the local position of this point on the table. Then we need to convert these local coordinates (relative to the table) into global coordinates (relative to the classroom). This process takes into account the position, rotation and scale of the table in the room. This position is then adjusted relative to the camera view, using the camera&#39;s position, rotation, scale and field of view as factors. Finally, the position is projected onto the 2D screen.</p> <h2 id="overview" class="text-2xl font-bold text-gray-100 mb-2 mt-8">Rasterisation</h2> <p class="text-lg text-gray-300 mb-1">To continue, just remember that a screen is a grid of millions of pixels of any colors. For now, our program renders only the points vertex of the triangles, which is not very interesting for now. The goal is to fill each triangle with the right color in the right place.
    Thanks to the previous operations, vertices are already placed on the screen, and pixels between them are also filled. However, if you apply this method naively, some hidden object faces may appear, as their triangles are drawn after those that should hide them. To avoid this, each point in the image is associated with an additional value: its distance from the camera. So, when you draw a pixel, you check that the recorded distance is not smaller than the one you&#39;re about to draw. The closest point is therefore the one that will be displayed on screen.</p> <img src="${f}" alt="Rasterisation" class="w-full"/> <h2 id="overview" class="text-2xl font-bold text-gray-100 mb-2 mt-8">Fragment Shading</h2> <p class="text-lg text-gray-300 mb-1">After the first two steps, we get a passable rendering, but there&#39;s no relief or volume to the image. For example, a sphere appears as a simple colored circle. To correct this, a third step is added to the pipeline: Fragment Shading. With light sources already placed in the environment (sun, lamp, etc.), this last major step can be carried out.
    Before going any further, it&#39;s important to understand a key concept in 3D: the normal of a surface. This is a vector that indicates the direction and sense of the surface at a given point (it is perpendicular to the surface). Using this notion, we can calculate the angle between the normal of each triangle and the direction of the light source. This angle is used to determine the quantity of light per cmÂ² reaching the surface (front = light intensity, perpendicular = 0). Other calculations are then performed to obtain the best possible rendering. For example, each object reacts differently to light, depending on its color, roughness (gloss) or refractive index.</p> <img src="${w}" alt="Fragment Shading" class="w-full"/> <h2 id="overview" class="text-2xl font-bold text-gray-100 mb-2 mt-8">Conclusion</h2> <p class="text-lg text-gray-300 mb-1">This article is just an overview of the world of 3D rendering engines.  We hope it has inspired you to find out more about this incredibly complex field. We could have talked about UV maps, which allow objects to be non-monochrome, smooth shading, which gives rounded shapes with fewer triangles, normal maps, which create the illusion of more complex geometries, or ray tracing, another rendering technology that simulates light in a very realistic way. That&#39;s why we invite you to learn more about this field.</p> <section class="mt-8"><h2 class="text-2xl font-bold text-gray-100 mb-2">Sources</h2> <ul class="text-lg text-gray-300 list-disc ml-6"><li><a href="https://www.youtube.com/watch?v=C8YtdC8mxTU" class="text-blue-400 hover:underline" target="_blank">How do Video Game Graphics Work?</a></li> <li><a href="https://en.wikipedia.org/wiki/Shader#Vertex_shaders" class="text-blue-400 hover:underline" target="_blank">Vertex Shaders</a></li> <li><a href="https://en.wikipedia.org/wiki/Graphics_pipeline" class="text-blue-400 hover:underline" target="_blank">Graphics Pipeline</a></li> <li><a href="https://en.wikipedia.org/wiki/3D_projection" class="text-blue-400 hover:underline" target="_blank">3D projection</a></li> <li><a href="https://en.wikipedia.org/wiki/3D_rendering" class="text-blue-400 hover:underline" target="_blank">3D Rendering</a></li></ul></section>`;return{c(){e=h("main"),e.innerHTML=i,this.h()},l(t){e=c(t,"MAIN",{class:!0,"data-svelte-h":!0}),d(e)!=="svelte-8f4p5y"&&(e.innerHTML=i),this.h()},h(){p(e,"class","p-6 max-w-4xl mx-auto")},m(t,s){m(t,e,s)},p:a,i:a,o:a,d(t){t&&g(e)}}}class v extends n{constructor(e){super(),l(this,e,null,x,r,{})}}export{v as component};
